# Generated from PythonGrammar.g4 by ANTLR 4.13.2
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO


def serializedATN():
    return [
        4,0,12,99,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,
        6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,1,0,1,0,1,1,1,
        1,1,2,3,2,31,8,2,1,2,1,2,3,2,35,8,2,1,2,1,2,1,3,4,3,40,8,3,11,3,
        12,3,41,1,3,1,3,1,4,1,4,5,4,48,8,4,10,4,12,4,51,9,4,1,4,1,4,1,5,
        1,5,1,5,1,5,1,5,5,5,60,8,5,10,5,12,5,63,9,5,1,5,1,5,1,5,1,5,1,5,
        1,5,1,6,1,6,1,6,1,7,1,7,1,7,1,7,1,7,1,8,1,8,1,9,4,9,82,8,9,11,9,
        12,9,83,1,10,1,10,5,10,88,8,10,10,10,12,10,91,9,10,1,11,4,11,94,
        8,11,11,11,12,11,95,1,11,1,11,1,61,0,12,1,1,3,2,5,3,7,4,9,5,11,6,
        13,7,15,8,17,9,19,10,21,11,23,12,1,0,5,2,0,9,9,32,32,2,0,10,10,13,
        13,1,0,48,57,3,0,65,90,95,95,97,122,4,0,48,57,65,90,95,95,97,122,
        106,0,1,1,0,0,0,0,3,1,0,0,0,0,5,1,0,0,0,0,7,1,0,0,0,0,9,1,0,0,0,
        0,11,1,0,0,0,0,13,1,0,0,0,0,15,1,0,0,0,0,17,1,0,0,0,0,19,1,0,0,0,
        0,21,1,0,0,0,0,23,1,0,0,0,1,25,1,0,0,0,3,27,1,0,0,0,5,30,1,0,0,0,
        7,39,1,0,0,0,9,45,1,0,0,0,11,54,1,0,0,0,13,70,1,0,0,0,15,73,1,0,
        0,0,17,78,1,0,0,0,19,81,1,0,0,0,21,85,1,0,0,0,23,93,1,0,0,0,25,26,
        1,0,0,0,26,2,1,0,0,0,27,28,1,0,0,0,28,4,1,0,0,0,29,31,5,13,0,0,30,
        29,1,0,0,0,30,31,1,0,0,0,31,32,1,0,0,0,32,34,5,10,0,0,33,35,3,7,
        3,0,34,33,1,0,0,0,34,35,1,0,0,0,35,36,1,0,0,0,36,37,6,2,0,0,37,6,
        1,0,0,0,38,40,7,0,0,0,39,38,1,0,0,0,40,41,1,0,0,0,41,39,1,0,0,0,
        41,42,1,0,0,0,42,43,1,0,0,0,43,44,6,3,1,0,44,8,1,0,0,0,45,49,5,35,
        0,0,46,48,8,1,0,0,47,46,1,0,0,0,48,51,1,0,0,0,49,47,1,0,0,0,49,50,
        1,0,0,0,50,52,1,0,0,0,51,49,1,0,0,0,52,53,6,4,2,0,53,10,1,0,0,0,
        54,55,5,39,0,0,55,56,5,39,0,0,56,57,5,39,0,0,57,61,1,0,0,0,58,60,
        9,0,0,0,59,58,1,0,0,0,60,63,1,0,0,0,61,62,1,0,0,0,61,59,1,0,0,0,
        62,64,1,0,0,0,63,61,1,0,0,0,64,65,5,39,0,0,65,66,5,39,0,0,66,67,
        5,39,0,0,67,68,1,0,0,0,68,69,6,5,2,0,69,12,1,0,0,0,70,71,5,105,0,
        0,71,72,5,102,0,0,72,14,1,0,0,0,73,74,5,101,0,0,74,75,5,108,0,0,
        75,76,5,115,0,0,76,77,5,101,0,0,77,16,1,0,0,0,78,79,5,61,0,0,79,
        18,1,0,0,0,80,82,7,2,0,0,81,80,1,0,0,0,82,83,1,0,0,0,83,81,1,0,0,
        0,83,84,1,0,0,0,84,20,1,0,0,0,85,89,7,3,0,0,86,88,7,4,0,0,87,86,
        1,0,0,0,88,91,1,0,0,0,89,87,1,0,0,0,89,90,1,0,0,0,90,22,1,0,0,0,
        91,89,1,0,0,0,92,94,7,0,0,0,93,92,1,0,0,0,94,95,1,0,0,0,95,93,1,
        0,0,0,95,96,1,0,0,0,96,97,1,0,0,0,97,98,6,11,2,0,98,24,1,0,0,0,9,
        0,30,34,41,49,61,83,89,95,3,1,2,0,0,1,0,6,0,0
    ]

class PythonGrammar(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    INDENT = 1
    DEDENT = 2
    NEWLINE = 3
    SPACES = 4
    COMMENT = 5
    MULTILINE_COMMENT = 6
    IF = 7
    ELSE = 8
    ASSIGN = 9
    NUMBER = 10
    IDENTIFIER = 11
    WS = 12

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'if'", "'else'", "'='" ]

    symbolicNames = [ "<INVALID>",
            "INDENT", "DEDENT", "NEWLINE", "SPACES", "COMMENT", "MULTILINE_COMMENT", 
            "IF", "ELSE", "ASSIGN", "NUMBER", "IDENTIFIER", "WS" ]

    ruleNames = [ "INDENT", "DEDENT", "NEWLINE", "SPACES", "COMMENT", "MULTILINE_COMMENT", 
                  "IF", "ELSE", "ASSIGN", "NUMBER", "IDENTIFIER", "WS" ]

    grammarFileName = "PythonGrammar.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.13.2")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


        # Stack to track indentation levels
        indent_stack = [0]
        pending_dedents = []

        def handle_indentation(self, new_indent):
            current_indent = self.indent_stack[-1]
            if new_indent > current_indent:
                self.indent_stack.append(new_indent)
                self.emit_token(self.INDENT)
            elif new_indent < current_indent:
                while self.indent_stack and new_indent < self.indent_stack[-1]:
                    self.indent_stack.pop()
                    self.pending_dedents.append(self.DEDENT)
            elif new_indent != current_indent:
                raise Exception(f"Invalid indentation level: {new_indent}")
        
        def emit_pending_dedents(self):
            for dedent in self.pending_dedents:
                self.emit_token(dedent)
            self.pending_dedents.clear()

        def emit_token(self, token_type):
            t = self._factory.create(self._tokenFactorySourcePair, token_type, "", Lexer.DEFAULT_TOKEN_CHANNEL,
                                     self._tokenStartCharIndex, self._input.index - 1,
                                     self._tokenStartLine, self._tokenStartColumn)
            self._token = t
            self.emit()


    def action(self, localctx:RuleContext, ruleIndex:int, actionIndex:int):
        if self._actions is None:
            actions = dict()
            actions[2] = self.NEWLINE_action 
            self._actions = actions
        action = self._actions.get(ruleIndex, None)
        if action is not None:
            action(localctx, actionIndex)
        else:
            raise Exception("No registered action for:" + str(ruleIndex))


    def NEWLINE_action(self, localctx:RuleContext , actionIndex:int):
        if actionIndex == 0:

                    handleIndentation(getText());
                    emitPendingDedents();
                
     


